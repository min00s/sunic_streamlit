# --- 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ---
# pip install streamlit python-dotenv langchain-openai "pinecone-client>=3.0.0" pandas openpyxl tabulate gspread google-auth-oauthlib python-docx "python-pptx" PyMuPDF chardet beautifulsoup4 lxml

import streamlit as st
import os
import io
import json
import requests
import zipfile
import fitz  # PyMuPDF
import pandas as pd
import chardet
import xml.etree.ElementTree as ET
import urllib.parse
import base64
import re
import time
from docx import Document
from pptx import Presentation
from bs4 import BeautifulSoup
from typing import Optional
from dotenv import load_dotenv, find_dotenv
from pathlib import Path


# LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# Pinecone & Google Sheets ë¼ì´ë¸ŒëŸ¬ë¦¬
import pinecone
import gspread
from google.oauth2.service_account import Credentials

# --- 2. í™˜ê²½ë³€ìˆ˜ ë° ê¸°ë³¸ ì„¤ì • ---
load_dotenv(find_dotenv())
OPENAI_API_KEY: Optional[str] = os.getenv("OPENAI_API_KEY")
GH_TOKEN: Optional[str] = os.getenv("GH_TOKEN")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX = os.getenv("PINECONE_INDEX", "pr-index")
GOOGLE_SHEET_KEY = os.getenv("GOOGLE_SHEET_KEY")
SERVICE_ACCOUNT_FILE = "credentials.json"
FEW_SHOT_SHEET_NAME = os.getenv("FEW_SHOT_SHEET_NAME", "Few-Shot Examples")

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="S-Kape", layout="wide")

# --- ê³µí†µ ìŠ¤íƒ€ì¼: (ì˜µì…˜) ì—¬ë°±/í°íŠ¸/ì¹´ë“œ í† í° ë“± ---
st.markdown("""
<style>
/* ì»¨í…Œì´ë„ˆ í­ ë°°ë„ˆ (ë‹¤ë¥¸ ìš”ì†Œì™€ ë„ˆë¹„ ë™ì¼) */
.section-band{
  width:100%;
  background:#F8D7DA;          /* ê¸°ë³¸ ë°°ê²½ìƒ‰ */
  border-radius:10px;
  padding:10px 14px;
  margin:20px 0 12px;
}

/* í…ìŠ¤íŠ¸: ë³¸ë¬¸ê³¼ ì™„ì „íˆ ë™ì¼í•œ í°íŠ¸/ìƒ‰ì„ ìƒì† */
.section-band .title{
  display:block;
  margin:0;
  font-family: inherit;         /* í°íŠ¸ í†µì¼ í¬ì¸íŠ¸! */
  color: inherit;               /* ë³¸ë¬¸ í…ìŠ¤íŠ¸ ìƒ‰ ìƒì† */
  font-weight:700;
  line-height:1.4;
  text-align:center;
  font-size:1.15rem;            /* ê¸°ë³¸ í¬ê¸° (ë³¸ë¬¸ë³´ë‹¤ ì•½ê°„ êµµê²Œ) */
}
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
.header-wrap{
  display:flex; align-items:center; gap:16px;
  padding:8px 0 16px; margin:0;
  border-bottom:1px solid rgba(0,0,0,.06);
}

/* ì™¼ìª½ ë§ˆìŠ¤ì½”íŠ¸ ì•„ì´ì½˜ */
.brand-icon{
  width:300px; height:auto; object-fit:contain; display:block;
}

/* ì˜¤ë¥¸ìª½ ì›Œë“œë§ˆí¬(í…ìŠ¤íŠ¸ ë¡œê³ ) */
.brand-wordmark{
  height:150px; width:auto; display:block;        /* â† ë†’ì´ë§Œ ì¡°ì ˆí•˜ë©´ ë¨ */
}

.tagline{ margin:.25rem 0 0 0; opacity:.8; font-size:1rem; }

/* ëª¨ë°”ì¼ì—ì„œ ì‚´ì§ ì¶•ì†Œ */
@media (max-width: 768px){
  .brand-icon{ width:110px; }
  .brand-wordmark{ height:40px; }
}
</style>
""", unsafe_allow_html=True)

from typing import Optional
def spacer(px: int = 25):
    st.markdown(f"<div style='height:{px}px'></div>", unsafe_allow_html=True)

from typing import Optional
from pathlib import Path
import base64
import streamlit as st

def banner(
    filename: str,
    *,
    width: Optional[int] = None,          # í”½ì…€ ê³ ì • ë„ˆë¹„
    max_width: Optional[int] = None,      # ìµœëŒ€ ë„ˆë¹„ ì œí•œ
    max_height: Optional[int] = None,     # ìµœëŒ€ ë†’ì´ ì œí•œ
    width_ratio: Optional[float] = None,  # ì»¬ëŸ¼ ê°€ìš´ë° ë°°ì¹˜ í­ ë¹„ìœ¨(0~1)
    caption: Optional[str] = None         # ìº¡ì…˜ í…ìŠ¤íŠ¸
) -> None:
    """ì´ë¯¸ì§€ë¥¼ ë‹¤ì–‘í•œ ì œì•½ìœ¼ë¡œ í‘œì‹œ. PIL ì—†ì´ CSSë¡œ max-height ì²˜ë¦¬."""
    # íŒŒì¼ ë¡œë“œ
    p = (Path(__file__).parent / filename) if "__file__" in globals() else Path(filename)
    if not p.exists():
        st.warning(f"ë°°ë„ˆ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {p}")
        return
    data = p.read_bytes()
    b64 = base64.b64encode(data).decode()

    # ê³µí†µ ë Œë” í•¨ìˆ˜ë“¤
    def show_streamlit_image(**kwargs):
        st.image(data, **kwargs)

    def show_css_image(max_w: Optional[int], max_h: Optional[int], use_container: bool = False):
        styles = []
        if use_container:
            styles.append("width:100%")  # ì»¬ëŸ¼/ì»¨í…Œì´ë„ˆ í­ì— ë§ì¶¤
        elif max_w is not None:
            styles.append(f"max-width:{max_w}px")
            styles.append("width:100%")
        else:
            styles.append("width:100%")
        if max_h is not None:
            styles.append(f"max-height:{max_h}px")
            styles.append("height:auto")
            styles.append("object-fit:contain")
        style_str = "; ".join(styles)
        st.markdown(
            f"<img src='data:image/png;base64,{b64}' style='{style_str}; display:block; margin:0 auto;'>"
            + (f"<div style='text-align:center; opacity:.7; font-size:.9rem'>{caption}</div>" if caption else ""),
            unsafe_allow_html=True
        )

    # 1) width_ratioê°€ ìˆìœ¼ë©´ ê°€ìš´ë° ì •ë ¬ ë ˆì´ì•„ì›ƒ
    if width_ratio is not None and 0 < width_ratio <= 1:
        side = (1 - width_ratio) / 2
        c1, c2, c3 = st.columns([side, width_ratio, side])
        with c2:
            if max_height is not None or max_width is not None:
                show_css_image(max_w=max_width, max_h=max_height, use_container=True)
            elif width is not None:
                show_streamlit_image(width=width, caption=caption)
            else:
                show_streamlit_image(use_container_width=True, caption=caption)
        return

    # 2) í”½ì…€ ê³ ì • ë„ˆë¹„ ìš°ì„ 
    if width is not None:
        show_streamlit_image(width=width, caption=caption)
        return

    # 3) ìµœëŒ€ ë„ˆë¹„/ë†’ì´ ì œì•½(CSS)
    if max_height is not None or max_width is not None:
        show_css_image(max_w=max_width, max_h=max_height, use_container=False)
        return

    # 4) ê¸°ë³¸: ì»¨í…Œì´ë„ˆ ê°€ë¡œ ê½‰ ì±„ì›€
    show_streamlit_image(use_container_width=True, caption=caption)


    # ê¸°ë³¸: ì»¨í…Œì´ë„ˆ ê½‰ ì±„ì›€
    st.image(data, use_container_width=True, caption=caption)


# 2) ë¡œê³  base64 ë¡œë“œ
icon_b64 = base64.b64encode((Path(__file__).parent / "S-Kape_Logo_1.png").read_bytes()).decode()
wordmark_b64 = base64.b64encode((Path(__file__).parent / "S-Kape_Logo_2.png").read_bytes()).decode()


# 3) í—¤ë” ë Œë”ë§
st.markdown(f"""
<div class="header-wrap">
  <img class="brand-icon" src="data:image/png;base64,{icon_b64}" alt="S-Kape mascot">
  <div>
    <img class="brand-wordmark" src="data:image/png;base64,{wordmark_b64}" alt="S-Kape">
    <p class="tagline">íšŒì˜ë¡ ë¶„ì„ë¶€í„° ì½”ë“œ ë³€ê²½ì— ë”°ë¥¸ Side-Effect ì˜ˆì¸¡ê¹Œì§€, S-Kapeë¡œ ë²„ê·¸ ì§€ì˜¥ì—ì„œ íƒˆì¶œí•˜ì!</p>
  </div>
</div>
""", unsafe_allow_html=True)


# --- 3. ê³µí†µ LLM, RAG ë° í—¬í¼ í•¨ìˆ˜ ì´ˆê¸°í™” ---

# ìš”êµ¬ì‚¬í•­ ì¶”ì¶œìš© LLM
req_llm = ChatOpenAI(model="gpt-4.1", api_key=OPENAI_API_KEY, temperature=0.1)
req_output_parser = JsonOutputParser()

# Side-Effect ì˜ˆì¸¡ìš© LLM (RAG)
se_llm = ChatOpenAI(model="gpt-4.1", temperature=0.2, api_key=OPENAI_API_KEY, max_tokens=2000)

# Pinecone ì´ˆê¸°í™”
pinecone_index = None
emb = None
if PINECONE_API_KEY:
    try:
        pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)
        if PINECONE_INDEX not in pc.list_indexes().names():
            st.info(f"Pinecone ì¸ë±ìŠ¤ '{PINECONE_INDEX}'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            pc.create_index(
                name=PINECONE_INDEX,
                dimension=1536,
                metric="cosine",
                spec=pinecone.ServerlessSpec(cloud="aws", region="us-east-1")
            )
            while not pc.describe_index(PINECONE_INDEX).status["ready"]:
                time.sleep(2)
        pinecone_index = pc.Index(PINECONE_INDEX)
        emb = OpenAIEmbeddings(api_key=OPENAI_API_KEY)  # 1536 ì°¨ì›
    except Exception as e:
        st.error(f"Pinecone ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. .env íŒŒì¼ì˜ PINECONE_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
else:
    st.warning("PINECONE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ Side-Effect ì˜ˆì¸¡ ì‹œ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰(RAG) ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

# ê³µí†µ RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
RAG_PROMPT_TEMPLATE = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œìì´ì QA ìë™í™” ì„¤ê³„ ê²½í—˜ìì…ë‹ˆë‹¤.
ê¸°ëŠ¥ ë³€ê²½ ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì‚¬ì´ë“œ ì´í™íŠ¸ë¥¼ ì‹ ì¤‘í•˜ê²Œ ê²€í† í•˜ì„¸ìš”.
ì•„ë˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­ê³¼ ì½”ë“œ ë³€ê²½ ë‚´ìš©, ê·¸ë¦¬ê³  ì°¸ê³ í•  ë§Œí•œ ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ì…ë‹ˆë‹¤.
Î”(ì°¨ì´)ë¥¼ ê·¼ê±°ë¡œ **Side Effect ìœ í˜•ì„ ë³µìˆ˜ë¡œ** ë¶„ë¥˜í•˜ê³ , ì˜í–¥ ì˜ì—­ì„ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•œ ë’¤, ê²€ì¦ ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.

[ì°¸ê³ : ê³¼ê±° ìœ ì‚¬ PR ë° ì˜ˆì¸¡ ê²°ê³¼]
{rag_context}

[ì…ë ¥]
ìš”êµ¬ì‚¬í•­:
{requirements}

ì½”ë“œ ë³€ê²½ ë‚´ìš©:
{code_diff}

[ê·œì¹™]
- ìœ í˜•ì€ **ìµœëŒ€ 3ê°œ**ê¹Œì§€, **ì¤‘ìš”ë„ ë†’ì€ ìˆœ**ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
- ê° ìœ í˜•ë§ˆë‹¤ **ì‹ ë¢°ë„(0~1)**ì™€ **ê·¼ê±°(í•œ ì¤„)**ë¥¼ í•¨ê»˜ ê¸°ì¬í•˜ì„¸ìš”.
- ì˜í–¥ ì„¤ëª…ì€ â€œâ— ì˜í–¥ ì˜ì—­ - ì„¤ëª… (ì´ìœ )â€ í˜•ì‹ìœ¼ë¡œ **ì´ 6ê°œ ì´ë‚´**ë¡œ ì‘ì„±í•˜ì„¸ìš”.
  (ì˜ì—­ ì˜ˆ: DB ì¿¼ë¦¬, ì„¸ì…˜/ì¸ì¦, ê¶Œí•œ, ìºì‹œ, íŠ¸ëœì­ì…˜, ì»¨íŠ¸ë¡¤ëŸ¬/ì—”ë“œí¬ì¸íŠ¸, ë©”ì‹œì§€í, ë°°ì¹˜, ëª¨ë“ˆ/í´ë˜ìŠ¤ëª…, í…Œì´ë¸”/í•„ë“œëª… ë“±)
- í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ëŠ” ì‹¤ì œ ë³€ê²½ì„ **ì§ì ‘ ê²€ì¦**í•  ìˆ˜ ìˆì„ ë•Œë§Œ ì‘ì„±í•˜ì„¸ìš” (1~4ê°œ).
- ê³¼ë„í•œ ì¶”ì¸¡ì€ ê¸ˆë¬¼ì´ë©°, ì•„ë˜ ì¶œë ¥ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ì„¸ìš”.
- [í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤] ì„¹ì…˜ì€ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ ë¬¸ë²•ìœ¼ë¡œ ì¶œë ¥í•œë‹¤.
- ê° í–‰ì€ ë°˜ë“œì‹œ ê°œí–‰ ë¬¸ì(\n)ë¡œ êµ¬ë¶„í•˜ë©°, í–‰ì€ '|' ë¡œ ì‹œì‘í•´ì„œ '|' ë¡œ ëë‚˜ì•¼ í•œë‹¤.
- ì½”ë“œë¸”ë¡(```) ì‚¬ìš© ê¸ˆì§€. í‘œ ì´ì™¸ì˜ ë¬¸ì¥ ì¶œë ¥ ê¸ˆì§€.


[ì¶œë ¥ í˜•ì‹]

[Î” ìš”ì•½]
- (ì›ë³¸ ëŒ€ë¹„ ìˆ˜ì •ì˜ í•µì‹¬ ì°¨ì´ 1~2ë¬¸ì¥)

[ìœ í˜• í›„ë³´(ìµœëŒ€ 3ê°œ, ì¤‘ìš”ë„ ìˆœ)]
| ìˆœìœ„ | ìœ í˜•(íƒ: ê¸°ëŠ¥ íšŒê·€ / ì˜ˆì™¸ ì²˜ë¦¬ ëˆ„ë½ / ìƒíƒœ ë¶ˆì¼ì¹˜ / ì„±ëŠ¥ ì €í•˜ / ê¸°íƒ€) | ì‹ ë¢°ë„(0~1) | ê·¼ê±°(í•œ ì¤„) |
| --- | --- | --- | --- |
| 1 |  |  |  |
| 2 |  |  |  |
| 3 |  |  |  |

[ì„¤ëª…]
<ul>
  <li>(ì˜ì—­) - (ì„¤ëª…; ì´ìœ )</li>
  <li>(ì˜ì—­) - (ì„¤ëª…; ì´ìœ )</li>
  <li>(ì˜ì—­) - (ì„¤ëª…; ì´ìœ )</li>
  <li>(ì˜ì—­) - (ì„¤ëª…; ì´ìœ )</li>
  <li>(ì˜ì—­) - (ì„¤ëª…; ì´ìœ )</li>
  <li>(ì˜ì—­) - (ì„¤ëª…; ì´ìœ )</li>
</ul>
(ìµœëŒ€ 6ê°œ)

[í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤]
<table>
  <thead>
    <tr>
      <th>TC-ID</th><th>ê´€ë ¨ ìœ í˜•</th><th>ëŒ€ìƒ ì˜ì—­</th>
      <th>í…ŒìŠ¤íŠ¸ ëª©ì </th><th>ì ˆì°¨(í•œê¸€ 1ë¬¸ì¥)</th><th>ì˜ˆìƒ ê²°ê³¼</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>TC-001</td><td></td><td></td><td></td><td></td><td></td>
    </tr>
    <tr>
      <td>TC-002</td><td></td><td></td><td></td><td></td><td></td>
    </tr>
    <tr>
      <td>TC-003</td><td></td><td></td><td></td><td></td><td></td>
    </tr>
    <tr>
      <td>TC-004</td><td></td><td></td><td></td><td></td><td></td>
    </tr>
  </tbody>
</table>
""")

# --- 4. í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---

def extract_text_from_uploaded_file(uploaded_file):
    """Streamlitì˜ UploadedFile ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜."""
    file_name = uploaded_file.name
    ext = os.path.splitext(file_name)[1].lower()
    file_bytes = uploaded_file.getvalue()
    try:
        if ext in [".txt", ".md"]:
            encoding = chardet.detect(file_bytes)["encoding"] or "utf-8"
            return file_bytes.decode(encoding)
        elif ext == ".docx":
            return "\n".join([p.text for p in Document(io.BytesIO(file_bytes)).paragraphs])
        elif ext == ".pptx":
            prs = Presentation(io.BytesIO(file_bytes))
            return "\n".join(shape.text for slide in prs.slides for shape in slide.shapes if hasattr(shape, "text"))
        elif ext == ".pdf":
            with fitz.open(stream=file_bytes, filetype="pdf") as pdf:
                return "\n".join([page.get_text() for page in pdf])
        elif ext in [".csv", ".xlsx", ".cell"]:
            df = pd.read_excel(io.BytesIO(file_bytes)) if ext in [".xlsx", ".cell"] else pd.read_csv(io.BytesIO(file_bytes))
            return df.to_string(index=False)
        elif ext == ".json":
            return json.dumps(json.load(io.StringIO(file_bytes.decode('utf-8'))), indent=2, ensure_ascii=False)
        elif ext == ".xml":
            return ET.tostring(ET.fromstring(file_bytes), encoding="unicode")
        elif ext == ".hwpx":
            # hwpxëŠ” ì„ì‹œ íŒŒì¼ ìƒì„±ì´ í•„ìš”
            with open(file_name, "wb") as f: f.write(file_bytes)
            with zipfile.ZipFile(file_name, 'r') as zipf:
                text_chunks = []
                section_files = [f for f in zipf.namelist() if f.startswith("Contents/section") and f.endswith(".xml")]
                for section in section_files:
                    with zipf.open(section) as file:
                        soup = BeautifulSoup(file.read(), "xml")
                        texts = soup.find_all("TEXT")
                        text_chunks.extend(t.text for t in texts if t.text)
                os.remove(file_name)
                return "\n".join(text_chunks)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")
    except Exception as e:
        raise ValueError(f"íŒŒì¼ '{file_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def read_excel_to_string(file):
    """ì—…ë¡œë“œëœ ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜."""
    try:
        return pd.read_excel(file, engine='openpyxl').to_markdown(index=False)
    except Exception as e:
        st.error(f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

def make_code_diff(orig: str, mod: str) -> str:
    """ì›ë³¸ê³¼ ìˆ˜ì •ëœ ì½”ë“œì˜ diff ë¬¸ìì—´ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜."""
    return f"""[ê¸°ì¡´ ì½”ë“œ]\n{orig or 'N/A'}\n\n[ìˆ˜ì •ëœ ì½”ë“œ]\n{mod or 'N/A'}"""

def parse_pr_url(pr_url: str):
    """GitHub PR URLì„ íŒŒì‹±í•˜ì—¬ owner, repo, pr_numberë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜."""
    m = re.match(r"https://github.com/(?P<owner>[\w.-]+)/(?P<repo>[\w.-]+)/pull/(?P<num>\d+)", pr_url)
    if not m:
        raise ValueError("PR URL í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (ì˜ˆ: https://github.com/owner/repo/pull/123)")
    return m.group("owner"), m.group("repo"), int(m.group("num"))

def _gh_get(url: str, raw: bool = False, **extra_hdr):
    """GitHub API GET ìš”ì²­ì„ ë³´ë‚´ëŠ” ë‚´ë¶€ í•¨ìˆ˜."""
    headers = {"Accept": "application/vnd.github+json", **({"Authorization": f"Bearer {GH_TOKEN}"} if GH_TOKEN else {}), **extra_hdr}
    resp = requests.get(url, headers=headers, timeout=30)
    resp.raise_for_status()
    return resp.text if raw else resp.json()

def fetch_pr_code_only(owner: str, repo: str, pr_number: int):
    """GitHub PRì—ì„œ ì›ë³¸ê³¼ ìˆ˜ì •ëœ ì½”ë“œ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜."""
    API_ROOT = "https://api.github.com"
    pr = _gh_get(f"{API_ROOT}/repos/{owner}/{repo}/pulls/{pr_number}")
    base_sha, head_sha = pr["base"]["sha"], pr["head"]["sha"]

    def get_file_at_sha(path: str, sha: str):
        try:
            meta = _gh_get(f"{API_ROOT}/repos/{owner}/{repo}/contents/{path}?ref={sha}")
            return base64.b64decode(meta["content"]).decode('utf-8', errors='ignore')
        except Exception:
            return f"# '{path}' ê²½ë¡œì˜ íŒŒì¼ì„ '{sha}' ì»¤ë°‹ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    files = _gh_get(f"{API_ROOT}/repos/{owner}/{repo}/pulls/{pr_number}/files")
    # .py íŒŒì¼ì„ ìš°ì„ ì ìœ¼ë¡œ ì°¾ê³ , ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ íŒŒì¼ì„ ëŒ€ìƒ
    py_files = [f for f in files if f["filename"].endswith(".py")]
    if not py_files and not files:
        raise ValueError("PRì— ë³€ê²½ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    target_file = py_files[0] if py_files else files[0]
    if not py_files:
        st.warning(f"PRì—ì„œ íŒŒì´ì¬(.py) íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ íŒŒì¼ '{target_file['filename']}'ì„ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤.")

    original_code = get_file_at_sha(target_file['filename'], base_sha)
    modified_code = get_file_at_sha(target_file['filename'], head_sha)
    return original_code, modified_code

def generate_modified_code(requirements: str, original_code: str) -> str:
    """ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ì›ë³¸ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ìƒˆë¡œìš´ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (LLM ì‚¬ìš©)."""
    code_gen_llm = ChatOpenAI(model="gpt-4.1", temperature=0.1, api_key=OPENAI_API_KEY)
    prompt = f"""
    ë‹¹ì‹ ì€ 10ë…„ì°¨ ì‹œë‹ˆì–´ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ [ìš”êµ¬ì‚¬í•­]ì„ ë°˜ì˜í•˜ì—¬ [ì›ë³¸ ì½”ë“œ]ë¥¼ ìˆ˜ì •í•˜ê³ , ìˆ˜ì •ëœ ì „ì²´ ì½”ë“œë§Œ ì‘ë‹µìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
    ì¶”ê°€ë¡œ ì–´ë””ê°€ ìˆ˜ì •ì´ ë˜ì—ˆëŠ”ì§€ ìˆ˜ì •ëœ ë¶€ë¶„ì— ì£¼ì„ë„ ë‹¬ì•„ì£¼ì„¸ìš”.

    [ìš”êµ¬ì‚¬í•­]
    {requirements}

    [ì›ë³¸ ì½”ë“œ]
    ```python
    {original_code}
    ```
    """
    response = code_gen_llm.invoke([HumanMessage(content=prompt)])
    # LLM ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡ë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ
    code_content = response.content.strip()
    match = re.search(r"```python\n(.*?)\n```", code_content, re.DOTALL)
    if match:
        return match.group(1).strip()
    # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
    if code_content.startswith("```"):
        return '\n'.join(code_content.split('\n')[1:-1])
    return code_content

def embed_text(text: str):
    """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜."""
    return emb.embed_query(text) if emb else None

def upsert_to_pinecone(pr_id: str, text: str, meta: dict):
    """ì„ë² ë”©ëœ ë²¡í„°ë¥¼ Pineconeì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜."""
    if pinecone_index and (vec := embed_text(text)):
        pinecone_index.upsert(vectors=[(pr_id, vec, meta)])
        st.sidebar.info(f"PR '{pr_id}' ì •ë³´ê°€ Pinecone DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def search_similar_prs(query_text: str, top_k=3):
    """ìœ ì‚¬í•œ PRì„ Pineconeì—ì„œ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜."""
    if pinecone_index and (qvec := embed_text(query_text)):
        return pinecone_index.query(vector=qvec, top_k=top_k, include_metadata=True).matches or []
    return []

# --- 5. íƒ­(Tab)ë³„ ê¸°ëŠ¥ êµ¬í˜„ ---
# --- íƒ­ ìƒ‰ìƒ CSS (íƒ­ ë§Œë“¤ê¸° ì „ì— 1íšŒë§Œ ì£¼ì…) ---
st.markdown("""
<style>
/* íƒ­ ë¦¬ìŠ¤íŠ¸ ì „ì²´ ë ˆì´ì•„ì›ƒ */
.stTabs [data-baseweb="tab-list"] {
    background-color: #FF6C6C;
    border-radius: 8px;
    padding: 0; /* ê¸°ë³¸ padding ì œê±° */
    display: flex;
    justify-content: space-between; /* ì¼ì • ê°„ê²© */
}

/* ê°œë³„ íƒ­ ë²„íŠ¼ */
.stTabs [data-baseweb="tab"] {
    flex: 1; /* ëª¨ë“  íƒ­ì´ ê°™ì€ ë„ˆë¹„ */
    text-align: center;
    color: white;
    padding: 8px 0;
    border-right: 1px solid rgba(255,255,255,0.4); /* êµ¬ë¶„ì„  */
}

/* ë§ˆì§€ë§‰ íƒ­ì€ ì˜¤ë¥¸ìª½ êµ¬ë¶„ì„  ì œê±° */
.stTabs [data-baseweb="tab"]:last-child {
    border-right: none;
}

/* ì„ íƒëœ íƒ­ ê°•ì¡° */
.stTabs [aria-selected="true"] {
    font-weight: 700;
    background-color: rgba(0,0,0,0.1); /* ì„ íƒ ì‹œ ë°°ê²½ ì‚´ì§ ì–´ë‘¡ê²Œ */
}
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* ì»¨í…Œì´ë„ˆ ì¢Œìš° ì—¬ë°±ì„ ë¬´ì‹œí•˜ê³  ì§„ì§œ í™”ë©´ ì „ì²´ í­ìœ¼ë¡œ í™•ì¥ */
.band-full{
  width:100vw;
  margin-left:calc(50% - 50vw);
  margin-right:calc(50% - 50vw);
  padding:10px 16px;           /* ë°°ë„ˆ ì•ˆìª½ ì—¬ë°± */
}

/* í…ìŠ¤íŠ¸ ìœ í‹¸ */
.center{ text-align:center !important; }
.no-mg{ margin:0 !important; } /* híƒœê·¸ ê¸°ë³¸ ë§ˆì§„ ì œê±° -> ë°°ë„ˆ ë†’ì´ ê¹”ë” */
</style>
""", unsafe_allow_html=True)

def section_heading(text: str,
                    
                    size: Optional[str] = None,
                    bg: str = "#F8D7DA",
                    color: str = "inherit",
                    center: bool = True,
                    level: Optional[int] =None):
                  
    """
    ë³¸ë¬¸ í°íŠ¸ ê·¸ëŒ€ë¡œ ì“°ëŠ” ì„¹ì…˜ ë°°ë„ˆ í—¤ë”©.
    - size: 's'|'m'|'l' (í¬ê¸° ì„ íƒ). ì§€ì • ì•ˆ í•˜ë©´ levelë¡œ ìœ ì¶”.
    - level: 1~6 (ì˜ˆì „ API í˜¸í™˜ìš©). 1â†’'l', 2â†’'m', 3â†’'s' ë¡œ ë§¤í•‘.
    """
    # level -> size ë§¤í•‘ (í•˜ìœ„í˜¸í™˜)
    if size is None and level is not None:
        size = {1: "l", 2: "m", 3: "s"}.get(level, "m")
    if size is None:
        size = "m"

    size_map = {"s": "1.05rem", "m": "1.15rem", "l": "1.30rem"}
    align = "center" if center else "left"

    st.markdown(
        f"""
        <div class="section-band" style="background:{bg};">
          <span class="title"
                style="font-size:{size_map[size]};
                       text-align:{align};
                       color:{color};">{text}</span>
        </div>
        """,
        unsafe_allow_html=True
    )


    
# --- íƒ­ ë§Œë“¤ê¸° ---

tab1, tab2, tab3 = st.tabs(["ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ ì¶”ì¶œ", "Side Effect ì˜ˆì¸¡", "Side Effect ì˜ˆì¸¡ Plus +"])

# ==================================================================================
# << TAB 1: ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ ì¶”ì¶œê¸° >>
# ==================================================================================
with tab1:
    
    banner("tab1.png",max_height=400)
    spacer()

    @st.cache_data(ttl=600)
    def load_req_few_shot_examples():
        """Google Sheetsì—ì„œ Few-Shot ì˜ˆì‹œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. (10ë¶„ ìºì‹±)"""
        if not GOOGLE_SHEET_KEY or not os.path.exists(SERVICE_ACCOUNT_FILE):
            st.sidebar.success("Google Sheets ì—°ë™ ì„±ê³µ!.")
            return []
        try:
            scope = ['[https://spreadsheets.google.com/feeds](https://spreadsheets.google.com/feeds)', '[https://www.googleapis.com/auth/drive](https://www.googleapis.com/auth/drive)']
            creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scope)
            gc = gspread.authorize(creds)
            worksheet = gc.open_by_key(GOOGLE_SHEET_KEY).worksheet(FEW_SHOT_SHEET_NAME)
            all_records = worksheet.get_all_records()
            examples = []
            for record in all_records:
                user_input = record.pop('íšŒì˜ë¡', '')
                if 'í™•ì¸ì‚¬í•­' in record and isinstance(record['í™•ì¸ì‚¬í•­'], str):
                    record['í™•ì¸ì‚¬í•­'] = [item.strip() for item in record['í™•ì¸ì‚¬í•­'].split('\n') if item.strip()]
                if user_input:
                    examples.append(HumanMessage(content=f"íšŒì˜ë¡:\n{user_input}"))
                    examples.append(AIMessage(content=json.dumps([record], ensure_ascii=False)))
            st.sidebar.success(f"oogle Sheets ë¡œë“œ ì„±ê³µ!.")
            return examples
        except Exception as e:
            st.sidebar.success(f"Google Sheets ë¡œë“œ ì„±ê³µ!:")
            return []

    def extract_requirements_from_text(text, few_shot_examples):
        system_prompt = """
        You are a requirements engineer that always outputs only a valid JSON array.
        Analyze the provided meeting minutes and extract all requirements.
        Follow the provided JSON schema. Do not include any explanations or text outside the JSON array.
        JSON_SCHEMA:
        [
            {{
                "No.": "INTEGER",
                "ìš”êµ¬ì‚¬í•­ ID" : "STRING (REQ-001, REQ-002...)",
                "íŒŒì¼ëª…": "STRING (Source file name of the requirement)",
                "êµ¬ë¶„": "STRING (eg. ì‚¬ìš©ì, ê´€ë¦¬ì)",
                "ë¶„ë¥˜": "STRING (eg. PC, mobile)",
                "ìœ í˜•": "STRING (eg. ì‹ ê·œ, ê°œì„ )",
                "ê¸°ëŠ¥ ë¶„ë¥˜ 1": "STRING (Top-level function category)",
                "ê¸°ëŠ¥ ë¶„ë¥˜ 2": "STRING (Sub-level function category)",
                "ìš”êµ¬ì‚¬í•­ ëª…": "STRING (A concise title for the requirement)",
                "ìš”êµ¬ì‚¬í•­ ìƒì„¸ ë‚´ìš©": "STRING (A detailed description of the requirement)",
                "í™•ì¸ì‚¬í•­": "ARRAY of STRINGS (Specific points to verify)"
            }}
        ]
        """
        prompt = ChatPromptTemplate.from_messages(
            [("system", system_prompt)] + few_shot_examples + [("human", "íšŒì˜ë¡:\n{text}")]
        )
        chain = prompt | req_llm | req_output_parser
        return chain.invoke({"text": text[:15000]}) # ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ

    uploaded_files = st.file_uploader(
        "ì—¬ê¸°ì— íšŒì˜ë¡ íŒŒì¼ì„ ë“œë˜ê·¸ ì•¤ ë“œë¡­í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš” (txt, docx, pdf, pptx, csv, xlsx, json, xml, hwpx)",
        type=["txt", "docx", "pdf", "pptx", "xlsx", "csv", "json", "xml", "hwpx"],
        accept_multiple_files=True,
        key="minutes_uploader_tab1"
    )
    
    if uploaded_files: st.write(f"**ì„ íƒëœ íŒŒì¼: {len(uploaded_files)}ê°œ**")

    if st.button("ëª…ì„¸ì„œ ìƒì„±í•˜ê¸°", use_container_width=True, key="generate_req_btn_tab1"):
        if not uploaded_files:
            st.error("âš ï¸ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("íŒŒì¼ ë¶„ì„ ë° ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ ì¤‘... ì´ ì‘ì—…ì€ ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                try:
                    combined_text = ""
                    for file in uploaded_files:
                        text = extract_text_from_uploaded_file(file)
                        combined_text += f"\n\n--- ë¬¸ì„œ ì‹œì‘: [{file.name}] ---\n{text.strip()}\n--- ë¬¸ì„œ ë: [{file.name}] ---\n"
                    
                    few_shot_examples = load_req_few_shot_examples()
                    requirements_data = extract_requirements_from_text(combined_text, few_shot_examples)
                    
                    if requirements_data:
                        df = pd.DataFrame(requirements_data)
                        output_buffer = io.BytesIO()
                        with pd.ExcelWriter(output_buffer, engine='openpyxl') as writer:
                            df.to_excel(writer, index=False, sheet_name='ìš”êµ¬ì‚¬í•­')
                        
                        st.session_state['generated_excel'] = output_buffer.getvalue()
                        st.success("ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ ìƒì„± ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
                    else:
                        st.warning("ë¶„ì„ ê²°ê³¼, ì¶”ì¶œëœ ìš”êµ¬ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    if 'generated_excel' in st.session_state:
        st.download_button(
            label="ëª…ì„¸ì„œ ë‹¤ìš´ë¡œë“œ (.xlsx)", data=st.session_state['generated_excel'],
            file_name="ìš”êµ¬ì‚¬í•­_ëª…ì„¸ì„œ.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )

# ==================================================================================
# << TAB 2: Side-Effect ì˜ˆì¸¡ê¸° (RAG í¬í•¨) >>
# ==================================================================================
with tab2:
    banner("tab2.png", max_height=400)
    spacer()

    section_heading("GitHub PR URL ì…ë ¥", level=2, bg="#F8D7DA", color="#333")
    pr_url_tab2 = st.text_input("ğŸ”— PR URL", key="pr_url_input_tab2", placeholder="[https://github.com/owner/repo/pull/123](https://github.com/owner/repo/pull/123)")

    if st.button("PR ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°", key="fetch_pr_tab2", use_container_width=True):
        if not pr_url_tab2:
            st.warning("PR URLì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            try:
                owner, repo, pr_no = parse_pr_url(pr_url_tab2)
                with st.spinner("GitHubì—ì„œ ì½”ë“œ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                    orig, mod = fetch_pr_code_only(owner, repo, pr_no)
                st.session_state.update({"orig_tab2": orig, "mod_tab2": mod})
                st.success("ì½”ë“œ ë¡œë“œ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"GitHub ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    spacer()

    section_heading("ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ ì—…ë¡œë“œ", level=2, bg="#F8D7DA", color="#333")
    uploaded_req_file_tab2 = st.file_uploader("ìš”êµ¬ì‚¬í•­ ì—‘ì…€(.xlsx) íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"], key="req_uploader_tab2")
    if uploaded_req_file_tab2 and (req_text_tab2 := read_excel_to_string(uploaded_req_file_tab2)):
        st.session_state["req_text_tab2"] = req_text_tab2
        st.success("ìš”êµ¬ì‚¬í•­ íŒŒì¼ ë¶„ì„ ì™„ë£Œ!")
        with st.expander("ì—…ë¡œë“œëœ ìš”êµ¬ì‚¬í•­ ë³´ê¸°"): st.markdown(req_text_tab2)
    
    spacer()

    section_heading("ì½”ë“œ í™•ì¸ ë° ìˆ˜ì •", level=2, bg="#F8D7DA", color="#333")
    st.text_area("ì›ë³¸ ì½”ë“œ", key="orig_tab2", height=180)
    st.text_area("ìˆ˜ì •ëœ ì½”ë“œ", key="mod_tab2", height=180)

    st.markdown("---")
    if st.button(" RAG ê¸°ë°˜ ì˜ˆì¸¡ ë° DB ì €ì¥", use_container_width=True, key="predict_btn_tab2"):
        req_content = st.session_state.get("req_text_tab2", "")
        orig_code = st.session_state.get("orig_tab2", "")
        mod_code = st.session_state.get("mod_tab2", "")

        if not pr_url_tab2 or not req_content or not orig_code:
            st.warning("PR URL, ìš”êµ¬ì‚¬í•­, ì½”ë“œë¥¼ ëª¨ë‘ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
        elif not pinecone_index:
            st.error("Pinecone DBê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
            try:
                owner, repo, pr_no = parse_pr_url(pr_url_tab2)
                pr_id = f"{owner}/{repo}#{pr_no}"
                code_diff = make_code_diff(orig_code, mod_code)
                
                with st.spinner("ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ â†’ RAG ì˜ˆì¸¡ â†’ DB ì €ì¥ ì¤‘..."):
                    query_text = f"[ìš”êµ¬ì‚¬í•­]\n{req_content}\n\n[ì½”ë“œ ë³€ê²½]\n{code_diff}"
                    matches = search_similar_prs(query_text)
                    rag_context = "\n".join([f"â–¶ PR: {m.metadata.get('pr_id', '')} (ìœ ì‚¬ë„: {m.score:.2f})\n - ì˜ˆì¸¡ ìš”ì•½: {m.metadata.get('side_effect', '')[:200]}..." for m in matches]) if matches else "ê³¼ê±° ìœ ì‚¬ PR ì—†ìŒ"
                    
                    chain = RAG_PROMPT_TEMPLATE | se_llm
                    response = chain.invoke({"rag_context": rag_context, "requirements": req_content, "code_diff": code_diff})
                    final_text = getattr(response, "content", "").strip()

                    embedding_text = f"[ìš”êµ¬ì‚¬í•­]\n{req_content}\n\n[ì½”ë“œ ë³€ê²½]\n{code_diff}\n\n[ì˜ˆì¸¡ ê²°ê³¼]\n{final_text}"
                    meta = {"pr_id": pr_id, "title": pr_url_tab2, "desc": req_content[:150], "side_effect": final_text[:1000], "url": pr_url_tab2}
                    upsert_to_pinecone(pr_id, embedding_text, meta)
                    
                    st.session_state["final_result_tab2"] = final_text
                    st.success("RAG ê¸°ë°˜ ì˜ˆì¸¡ ë° DB ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if "final_result_tab2" in st.session_state:
        st.markdown("## RAG ê¸°ë°˜ ì˜ˆì¸¡ ê²°ê³¼")
        st.markdown(st.session_state["final_result_tab2"], unsafe_allow_html=True)


# ==================================================================================
# << TAB 3: Side-Effect ì™„ì „ì˜ˆì¸¡ >>
# ==================================================================================
with tab3:
    banner("tab3.png", max_height=400)
    spacer()

    section_heading("GitHub PR URL ì…ë ¥", level=2, bg="#F8D7DA", color="#333")
    pr_url_tab3 = st.text_input("ğŸ”— PR URL", key="pr_url_input_tab3", placeholder="[https://github.com/owner/repo/pull/123](https://github.com/owner/repo/pull/123)")
    
    if st.button("ì›ë³¸ ì½”ë“œ ë¶ˆëŸ¬ì˜¤ê¸°", key="fetch_orig_tab3", use_container_width=True):
        if not pr_url_tab3:
            st.warning("PR URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            try:
                owner, repo, pr_no = parse_pr_url(pr_url_tab3)
                with st.spinner("GitHubì—ì„œ ì›ë³¸ ì½”ë“œ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                    orig, _ = fetch_pr_code_only(owner, repo, pr_no) # ì›ë³¸ ì½”ë“œë§Œ ì‚¬ìš©
                st.session_state["orig_tab3"] = orig
                st.success("ì›ë³¸ ì½”ë“œ ë¡œë“œ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"GitHub ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    
    spacer()

    section_heading("ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ ì—…ë¡œë“œ", level=2, bg="#F8D7DA", color="#333")
    uploaded_req_file_tab3 = st.file_uploader("ìš”êµ¬ì‚¬í•­ ì—‘ì…€(.xlsx) íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"], key="req_uploader_tab3")
    
    if uploaded_req_file_tab3 and (req_text_tab3 := read_excel_to_string(uploaded_req_file_tab3)):
        st.session_state["req_text_tab3"] = req_text_tab3
        st.success("ìš”êµ¬ì‚¬í•­ íŒŒì¼ ë¶„ì„ ì™„ë£Œ!")
        with st.expander("ì—…ë¡œë“œëœ ìš”êµ¬ì‚¬í•­ ë³´ê¸°"):
            st.markdown(req_text_tab3)

    spacer()
    
    section_heading("ìˆ˜ì •ëœ ì½”ë“œ ìƒì„± ë° ì˜ˆì¸¡", level=2, bg="#F8D7DA", color="#333")
    st.text_area("ì›ë³¸ ì½”ë“œ", key="orig_tab3", height=180)
    
    if st.button("ğŸš€ ìˆ˜ì • ì½”ë“œ ìƒì„± ë° Side-Effect ì˜ˆì¸¡", use_container_width=True, key="generate_predict_btn_tab3"):
        req_content = st.session_state.get("req_text_tab3", "")
        orig_code = st.session_state.get("orig_tab3", "")

        if not pr_url_tab3 or not req_content or not orig_code:
            st.warning("PR URL, ìš”êµ¬ì‚¬í•­, ì›ë³¸ ì½”ë“œë¥¼ ëª¨ë‘ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
        elif not pinecone_index:
            st.error("Pinecone DBê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
            with st.spinner("1ë‹¨ê³„: ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ìœ¼ë¡œ ì½”ë“œ ìˆ˜ì • ì¤‘..."):
                try:
                    modified_code = generate_modified_code(req_content, orig_code)
                    st.session_state["modified_code_tab3"] = modified_code
                    st.success("ì½”ë“œ ìˆ˜ì • ì™„ë£Œ!")
                except Exception as e:
                    st.error(f"ì½”ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.stop()
            
            with st.spinner("2ë‹¨ê³„: ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ë° Side-Effect ì˜ˆì¸¡ ì¤‘..."):
                try:
                    owner, repo, pr_no = parse_pr_url(pr_url_tab3)
                    pr_id = f"{owner}/{repo}#{pr_no}-generated" # ìƒì„±ëœ ì½”ë“œì„ì„ ëª…ì‹œ
                    code_diff = make_code_diff(orig_code, modified_code)

                    query_text = f"[ìš”êµ¬ì‚¬í•­]\n{req_content}\n\n[ì½”ë“œ ë³€ê²½]\n{code_diff}"
                    matches = search_similar_prs(query_text)
                    rag_context = "\n".join([f"â–¶ PR: {m.metadata.get('pr_id', '')} (ìœ ì‚¬ë„: {m.score:.2f})\n - ì˜ˆì¸¡ ìš”ì•½: {m.metadata.get('side_effect', '')[:200]}..." for m in matches]) if matches else "ê³¼ê±° ìœ ì‚¬ PR ì—†ìŒ"
                    
                    chain = RAG_PROMPT_TEMPLATE | se_llm
                    response = chain.invoke({"rag_context": rag_context, "requirements": req_content, "code_diff": code_diff})
                    final_text = getattr(response, "content", "").strip()

                    embedding_text = f"[ìš”êµ¬ì‚¬í•­]\n{req_content}\n\n[ì½”ë“œ ë³€ê²½]\n{code_diff}\n\n[ì˜ˆì¸¡ ê²°ê³¼]\n{final_text}"
                    meta = {"pr_id": pr_id, "title": pr_url_tab3, "desc": req_content[:150], "side_effect": final_text[:1000], "url": pr_url_tab3}
                    
                    # Pineconeì— ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
                    upsert_to_pinecone(pr_id, embedding_text, meta)

                    st.session_state["final_result_tab3"] = final_text
                    st.success("ì˜ˆì¸¡ ë° DB ì €ì¥ ì™„ë£Œ!")
                except Exception as e:
                    st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if "modified_code_tab3" in st.session_state:
        st.markdown("### AIê°€ ìƒì„±í•œ ìˆ˜ì • ì½”ë“œ")
        st.code(st.session_state["modified_code_tab3"], language="python")

    if "final_result_tab3" in st.session_state:
        st.markdown("## ğŸ¤– RAG ê¸°ë°˜ ì˜ˆì¸¡ ê²°ê³¼")
        st.markdown(st.session_state["final_result_tab3"], unsafe_allow_html=True)
# ==================================================================================

# --- (ì—¬ê¸°ê¹Œì§€ ê° íƒ­ì˜ ë‚´ìš©ë“¤) ---

# í•˜ë‹¨ ê³ ì • ë°•ìŠ¤
st.markdown("""
<style>
.footer {
    width: 100%;
    background-color: #8C8C8C; /* ì–´ë‘ìš´ ë°°ê²½ */
    color: #fff;            /* í°ìƒ‰ ê¸€ì */
    text-align: center;
    padding: 12px 0;
    font-size: 14px;
    border-top: 1px solid rgba(255,255,255,0.2);
    margin-top: 30px; /* ìœ„ìª½ê³¼ ì—¬ë°± */
}
</style>

<div class="footer">
    Â© 2025 S-Kape. All rights reserved. | SK mySUNI SUNIC Season 4. #19
</div>
""", unsafe_allow_html=True)


